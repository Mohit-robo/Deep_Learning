{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally after reading a particular text, Humans can recognize some common entities like person name , date and so on. But to do the same with the aid of computers, we have to help the computer learn and do the task for us. To do so, we can avail services of `Natural Language Processing (NLP)` and `Machine Learning (ML)`. The role of NLP is to make possible for the computer to read text, communicate with humans , understand their sentiments and interpret it by knowing the patterns and rules of languages. And the role of ML is to help machines learn and improve in time.\n",
    "\n",
    "Like how we define a heartbeat as a two-part pumping action, we define the working of NER as a two-step process\n",
    "\n",
    "1. Identify the named entity \n",
    "2. Categorize the named entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from spacy.training.example import Example\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Blank Model\n",
    "\n",
    "The very first step in building a cutom model is to create a blank ‘en’ model. This blank model is built to carry out NER process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "output_dir=Path(\"ner/\")\n",
    "n_iter=100\n",
    "\n",
    "#load the model\n",
    "\n",
    "if model is not None:\n",
    "    nlp = spacy.load(model)  \n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp = spacy.blank('en')  \n",
    "    print(\"Created blank 'en' model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n",
    "\n",
    "First we need to create entity categories such as `Degree`, `School name`, `Location`, `Percentage` & `Date` and feed the NER model with relevant training data.\n",
    "\n",
    "Spacy library accepts the training data in the form of tuples containing text data and a dictionary. The dictionary should contain the start and end indices of the named entity in the text and category of the named entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [('Higher School Certificate, Parramatta Marist High School, Westmead (1998)',\n",
    "                {'entities':[(0,25,'degree'),(27,56,'school_name'),(58,66,'location'),(68,72,'date')]}),\n",
    "            \n",
    "            ('Bachelor of Business, University of Western Sydney (2005) ',\n",
    "            {'entities':[(0,20,'degree'),(22,43,'school_name'),(44,50,'location'),(52,56,'date')]}),\n",
    "            \n",
    "            ('2007–2010 BCA (Bachelor of Computer Application) from Khalsa college for women, Amritsar (Affiliated to Guru Nanak Dev University (G.N.D.U) India ',\n",
    "            {'entities':[(0,9,'date'),(12,50,'degree'),(54,78,'school_name'),(80,88,'location')]}),\n",
    "            \n",
    "            ('2010–2013 MCA (Masters in Computer Applications) from Amritsar College of Engineering, Amritsar (Affiliated to Punjab Technical University (P.T.U) India.',\n",
    "            {'entities':[(0,9,'date'),(10,48,'degree'),(54,85,'school_name'),(87,95,'location')]})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Set-up\n",
    "\n",
    "Next step is to set-up the pipeline with only NER using `create_pipe` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe('ner',last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Before starting to train the model, we have to add the categories of the named entities (Labels) to the ‘ner’ using `ner.add_label()` method and then we have to disable other pipeline components apart from ‘ner’ since these components should not get affected while training. we train the recognizer by disabling those components using `nlp.disable_pipes()` method.\n",
    "\n",
    "To train the ‘ner’ model, the model has to be looped over the training data for sufficient number of iterations. For that, we use `n_iter` which is set to 100. Inorder to ensure that the model does not make generalizations based on the order of the examples, we will shuffle the training data randomly before every iteration using `random.shuffle()` function.\n",
    "\n",
    "We use `tqdm()` function for creating Progress Meters or Progress Bars. Example class holds the information for one training instance. It stores two objects, one for holding the predictions of the pipeline and other for holding the reference data. `Example.from_dict(doc,annotations)` method is used to construct an Example object from the predicted document (doc) and the reference annotations provided as a dictionary (annotations).The `nlp_update()` function can be used to train the recognizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "        ## check if the labels are added  `ner.labels`\n",
    "\n",
    "example = []\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in tqdm(TRAIN_DATA):\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            nlp.update(\n",
    "                [example], \n",
    "                drop=0.5,  \n",
    "                sgd=optimizer,\n",
    "                losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "\n",
    "Save the model which is stored in the `output_dir` variable and export the model as a pkl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to ner\n"
     ]
    }
   ],
   "source": [
    "if output_dir is not None:\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)\n",
    "pickle.dump(nlp, open( \"education nlp.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date  ------>   2015\n",
      "date  ------>   2017\n",
      "school_name  ------>   BE Chemical Engineering\n",
      "school_name  ------>   Coimbatore Institute of Technology\n",
      "location  ------>   India\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"2015-2017, BE Chemical Engineering, Coimbatore Institute of Technology , India\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.label_+ '  ------>   ' + ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2015\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">date</span>\n",
       "</mark>\n",
       "-\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2017\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">date</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BE Chemical Engineering\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">school_name</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Coimbatore Institute of Technology\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">school_name</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">location</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `BE Chemical Engineering` is being categorised as `school_name`. Hence we assign entities manually in case they have not been recognised.\n",
    "\n",
    "`spacky.tokens.Span`  --> [: :] works normally like list comprehension in python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "s1 = Span(doc,3,7,label = 'degree')\n",
    "\n",
    "doc.set_ents([s1],default='unmodified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date  ------>   2015\n",
      "date  ------>   2017\n",
      "degree  ------>   , BE Chemical Engineering\n",
      "school_name  ------>   Coimbatore Institute of Technology\n",
      "location  ------>   India\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.label_+ '  ------>   ' + ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('nlp': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "503eb6ff0f2c8590e2e97350de29f743bc442651deb326b2c30286532174cdfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
